{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Stock Analysis & Trading System - Colab Quickstart\n",
    "\n",
    "This notebook demonstrates the complete pipeline for stock analysis and backtesting:\n",
    "1. Mount Google Drive\n",
    "2. Install dependencies\n",
    "3. Load stock data (Parquet OHLCV files)\n",
    "4. Compute technical indicators (SMA, RSI)\n",
    "5. Run backtests with multiple strategies\n",
    "6. Scan for trading opportunities\n",
    "7. Launch interactive Dash UI\n",
    "\n",
    "**Note:** This system is optimized for Google Colab + Google Drive workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## 1. Setup: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify mount\n",
    "import os\n",
    "print(\"Drive mounted successfully!\" if os.path.exists('/content/drive/MyDrive') else \"Drive mount failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone-section"
   },
   "source": [
    "## 2. Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/vimala1500/sandt_v1.0.git\n",
    "%cd sandt_v1.0\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"\\nInstallation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-prep-section"
   },
   "source": [
    "## 3. Prepare Sample Data (Optional)\n",
    "\n",
    "If you don't have Parquet files in Google Drive yet, this cell creates sample data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create-sample-data"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Create sample data directory\n",
    "data_path = Path('/content/drive/MyDrive/stock_data')\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate sample OHLCV data for a few symbols\n",
    "def generate_sample_data(symbol, days=1000):\n",
    "    \"\"\"Generate sample OHLCV data.\"\"\"\n",
    "    dates = pd.date_range(end=pd.Timestamp.now(), periods=days, freq='D')\n",
    "    \n",
    "    # Generate random walk for prices\n",
    "    np.random.seed(hash(symbol) % 2**32)\n",
    "    returns = np.random.randn(days) * 0.02  # 2% daily volatility\n",
    "    close = 100 * np.exp(np.cumsum(returns))\n",
    "    \n",
    "    # Generate OHLCV\n",
    "    df = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'Open': close * (1 + np.random.randn(days) * 0.01),\n",
    "        'High': close * (1 + np.abs(np.random.randn(days)) * 0.02),\n",
    "        'Low': close * (1 - np.abs(np.random.randn(days)) * 0.02),\n",
    "        'Close': close,\n",
    "        'Volume': np.random.randint(1000000, 10000000, days)\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate sample data for a few symbols\n",
    "sample_symbols = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA']\n",
    "for symbol in sample_symbols:\n",
    "    df = generate_sample_data(symbol)\n",
    "    df.to_parquet(data_path / f'{symbol}.parquet', index=False)\n",
    "    print(f\"Created sample data for {symbol}\")\n",
    "\n",
    "print(f\"\\nSample data created in: {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "indicators-section"
   },
   "source": [
    "## 4. Compute Technical Indicators\n",
    "\n",
    "Calculate SMA and RSI indicators for all symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compute-indicators"
   },
   "outputs": [],
   "source": [
    "from data_loader import DataLoader\n",
    "from indicator_engine import IndicatorEngine\n",
    "\n",
    "# Initialize\n",
    "data_loader = DataLoader('/content/drive/MyDrive/stock_data')\n",
    "indicator_engine = IndicatorEngine('/content/drive/MyDrive/indicators')\n",
    "\n",
    "# List available symbols\n",
    "symbols = data_loader.list_available_symbols()\n",
    "print(f\"Found {len(symbols)} symbols: {symbols}\")\n",
    "\n",
    "# Load data\n",
    "print(\"\\nLoading stock data...\")\n",
    "data_dict = data_loader.load_multiple_symbols(symbols)\n",
    "print(f\"Loaded {len(data_dict)} symbols\")\n",
    "\n",
    "# Compute indicators\n",
    "print(\"\\nComputing indicators...\")\n",
    "indicator_engine.process_multiple_symbols(\n",
    "    data_dict,\n",
    "    sma_periods=[20, 50, 200],\n",
    "    rsi_periods=[14],\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "print(\"\\nIndicators computed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "backtest-section"
   },
   "source": [
    "## 5. Run Backtests\n",
    "\n",
    "Test multiple strategies across all symbols using Numba-accelerated backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-backtests"
   },
   "outputs": [],
   "source": [
    "from backtest_engine import BacktestEngine\n",
    "from strategy import DEFAULT_STRATEGIES\n",
    "\n",
    "# Initialize backtest engine\n",
    "backtest_engine = BacktestEngine('/content/drive/MyDrive/backtests')\n",
    "\n",
    "# Load indicators for backtesting\n",
    "data_with_indicators = {}\n",
    "for symbol in symbols:\n",
    "    data = indicator_engine.load_indicators(symbol)\n",
    "    if data is not None:\n",
    "        data_with_indicators[symbol] = data\n",
    "\n",
    "print(f\"Running backtests for {len(data_with_indicators)} symbols...\\n\")\n",
    "\n",
    "# Run backtests with default strategies\n",
    "strategy_configs = list(DEFAULT_STRATEGIES.values())\n",
    "results_df = backtest_engine.run_multiple_backtests(\n",
    "    data_with_indicators,\n",
    "    strategy_configs,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BACKTEST RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total backtests: {len(results_df)}\")\n",
    "print(f\"\\nAverage metrics:\")\n",
    "print(results_df[['cagr', 'sharpe_ratio', 'win_rate', 'max_drawdown']].mean())\n",
    "\n",
    "print(f\"\\n\\nTop 10 by Sharpe Ratio:\")\n",
    "print(results_df.nlargest(10, 'sharpe_ratio')[['symbol', 'strategy', 'sharpe_ratio', 'cagr', 'win_rate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scan-section"
   },
   "source": [
    "## 6. Run Live Scans\n",
    "\n",
    "Find stocks matching specific conditions with backtest performance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-scans"
   },
   "outputs": [],
   "source": [
    "from scanner import Scanner\n",
    "\n",
    "# Initialize scanner\n",
    "scanner = Scanner(indicator_engine, backtest_engine)\n",
    "\n",
    "# Scan for oversold stocks (RSI < 30)\n",
    "print(\"Scanning for oversold stocks (RSI < 30)...\")\n",
    "oversold = scanner.scan_rsi_oversold(symbols, rsi_period=14, threshold=30)\n",
    "print(f\"\\nFound {len(oversold)} oversold stocks:\")\n",
    "if len(oversold) > 0:\n",
    "    print(oversold)\n",
    "\n",
    "# Scan for overbought stocks (RSI > 70)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Scanning for overbought stocks (RSI > 70)...\")\n",
    "overbought = scanner.scan_rsi_overbought(symbols, rsi_period=14, threshold=70)\n",
    "print(f\"\\nFound {len(overbought)} overbought stocks:\")\n",
    "if len(overbought) > 0:\n",
    "    print(overbought)\n",
    "\n",
    "# Get top performers\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Top performers by Sharpe ratio (RSI strategy)...\")\n",
    "top = scanner.get_top_performers('rsi_meanrev', metric='sharpe_ratio', min_trades=5, top_n=10)\n",
    "if len(top) > 0:\n",
    "    print(top[['symbol', 'sharpe_ratio', 'cagr', 'win_rate', 'num_trades']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ui-section"
   },
   "source": [
    "## 7. Launch Interactive Dash UI\n",
    "\n",
    "Start the web-based UI for interactive analysis. Click the link to open the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch-ui"
   },
   "outputs": [],
   "source": [
    "# Note: To use Dash in Colab, you need ngrok or similar tunneling service\n",
    "# This is a basic example - for production use, set up proper tunneling\n",
    "\n",
    "from dash_ui import create_app\n",
    "\n",
    "# Create Dash app\n",
    "ui = create_app(\n",
    "    indicator_path='/content/drive/MyDrive/indicators',\n",
    "    backtest_path='/content/drive/MyDrive/backtests'\n",
    ")\n",
    "\n",
    "# For Colab, you would typically use:\n",
    "# !pip install pyngrok\n",
    "# from pyngrok import ngrok\n",
    "# public_url = ngrok.connect(8050)\n",
    "# print(f\"Dash app available at: {public_url}\")\n",
    "\n",
    "# Run in thread for Colab\n",
    "import threading\n",
    "\n",
    "def run_app():\n",
    "    ui.run(host='0.0.0.0', port=8050, debug=False)\n",
    "\n",
    "thread = threading.Thread(target=run_app)\n",
    "thread.daemon = True\n",
    "thread.start()\n",
    "\n",
    "print(\"Dash UI started!\")\n",
    "print(\"Note: In Colab, use ngrok for public URL. See code comments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage-section"
   },
   "source": [
    "## Usage Notes\n",
    "\n",
    "### Pipeline Modes\n",
    "\n",
    "You can run the pipeline in different modes using the `main.py` script:\n",
    "\n",
    "```python\n",
    "from main import Pipeline\n",
    "\n",
    "# Initialize\n",
    "pipeline = Pipeline(\n",
    "    data_path='/content/drive/MyDrive/stock_data',\n",
    "    indicator_path='/content/drive/MyDrive/indicators',\n",
    "    backtest_path='/content/drive/MyDrive/backtests'\n",
    ")\n",
    "\n",
    "# Run full pipeline\n",
    "pipeline.run_full_pipeline()\n",
    "\n",
    "# Or run individual stages\n",
    "pipeline.run_indicators_only()\n",
    "pipeline.run_backtests_only()\n",
    "pipeline.run_scan('rsi_oversold', threshold=20)\n",
    "```\n",
    "\n",
    "### Data Organization\n",
    "\n",
    "- **Stock Data**: `/content/drive/MyDrive/stock_data/*.parquet`\n",
    "- **Indicators**: `/content/drive/MyDrive/indicators/indicators.h5` and `config.json`\n",
    "- **Backtests**: `/content/drive/MyDrive/backtests/results.zarr`, `summary.parquet`, `metadata.json`\n",
    "\n",
    "### Adding Custom Strategies\n",
    "\n",
    "See `strategy.py` for examples. Add your strategy function to the `StrategyRegistry` class.\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "- Indicators and backtests are cached in Google Drive\n",
    "- Use Numba-accelerated functions for custom indicators\n",
    "- Zarr provides efficient chunked storage for large backtest results\n",
    "- HDF5 stores indicator time series efficiently"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
